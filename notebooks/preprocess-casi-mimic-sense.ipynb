{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary ###\n",
      "CASI: samples=16586, acronyms=37\n",
      "MIMIC-III: samples=17300, acronyms=37\n"
     ]
    }
   ],
   "source": [
    "# All of the files below result from running the preprocessing pipeline by Adams et al. (2020) on the raw CASI and MIMIC-III datasets.\n",
    "\n",
    "CASI_DIR = '/data/casi-sense' # Modify as needed\n",
    "casi_df = pd.read_csv(osp.join(CASI_DIR, 'preprocessed_dataset_window_10.csv'))\n",
    "sf_lf_map = json.load(open(osp.join(CASI_DIR, 'sf_lf_map.json'))) # Short-form to long-form \"sense\" \n",
    "labeled_sf_lf_map = pd.read_csv(osp.join(CASI_DIR, 'labeled_sf_lf_map.csv'))\n",
    "\n",
    "MIMIC_DIR = '/usr1/data/dataset/mimic-iii-sense' # Modify as needed\n",
    "mimic_df = pd.read_csv(osp.join(MIMIC_DIR, 'mimic_rs_dataset_preprocessed_window_10.csv'))\n",
    "mimic_sf_list = yaml.load(open(osp.join(MIMIC_DIR, 'mimic_sf.yaml')), Loader=yaml.FullLoader)\n",
    "\n",
    "# Filter out the acronyms that are not present in MIMIC-III, as done in Adams et al. (2020)\n",
    "casi_df = casi_df[casi_df['sf'].isin(mimic_sf_list)]\n",
    "\n",
    "# Sample at most 500 examples per acronym\n",
    "casi_df = casi_df.groupby('sf').apply(lambda x: x.sample(n=min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "mimic_df = mimic_df.groupby('sf').apply(lambda x: x.sample(n=min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print('### Summary ###')\n",
    "print(f'CASI: samples={casi_df.shape[0]}, acronyms={casi_df[\"sf\"].nunique()}')\n",
    "print(f'MIMIC-III: samples={mimic_df.shape[0]}, acronyms={mimic_df[\"sf\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sf                                                                 AMA\n",
       "target_lf                                       against medical advice\n",
       "sf_rep                                                            AMA.\n",
       "start_idx                                                        175.0\n",
       "end_idx                                                          178.0\n",
       "section                                                 IDENTIFICATION\n",
       "context              His wife works as a CPA. He is unemployed. He ...\n",
       "lf_in_sf                                                         False\n",
       "target_lf_sense                                 against medical advice\n",
       "tokenized_context    wife works cpa unemployed entered with long hi...\n",
       "sf_occurrences                                                     0.0\n",
       "trimmed_tokens       addiction heroin crack-cocaine drugs of choice...\n",
       "target_lf_idx                                                        2\n",
       "row_idx                                                           1832\n",
       "section_mapped                                   header=IDENTIFICATION\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casi_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Taking stratified split of MIMIC-III data:   0%|          | 0/37 [00:38<?, ?it/s, acronym=FSH]\n",
      "Taking stratified split of CASI data: 100%|██████████| 37/37 [00:00<00:00, 188.34it/s, acronym=FSH]\n",
      "Taking stratified split of MIMIC-III data:   0%|          | 0/37 [00:00<?, ?it/s, acronym=FSH]"
     ]
    }
   ],
   "source": [
    "# Take stratified split and only select the relevant columns\n",
    "casi_train = []\n",
    "casi_val = []\n",
    "casi_test = []\n",
    "\n",
    "mimic_train = []\n",
    "mimic_val = []\n",
    "mimic_test = []\n",
    "\n",
    "cols = ['sf', 'target_lf_sense', 'context']\n",
    "pbar = tqdm(mimic_sf_list, desc='Taking stratified split of CASI data')\n",
    "for sf in pbar:\n",
    "    pbar.set_postfix(acronym=sf)\n",
    "    casi_sf = casi_df[casi_df['sf'] == sf].reset_index(drop=True)\n",
    "    casi_sf = casi_sf[cols]\n",
    "    n_casi_sf = casi_sf.shape[0]\n",
    "    n_test = int(n_casi_sf * 0.2)\n",
    "    n_val = int(n_casi_sf * 0.2)\n",
    "    train_idx, test_idx = train_test_split(np.arange(n_casi_sf), test_size=n_test, random_state=42)\n",
    "    train_idx, val_idx = train_test_split(train_idx, test_size=n_val, random_state=42)\n",
    "    \n",
    "    casi_train += casi_sf.iloc[train_idx].to_dict(orient='records')\n",
    "    casi_val += casi_sf.iloc[val_idx].to_dict(orient='records')\n",
    "    casi_test += casi_sf.iloc[test_idx].to_dict(orient='records')\n",
    "\n",
    "pbar = tqdm(mimic_sf_list, desc='Taking stratified split of MIMIC-III data')\n",
    "for sf in mimic_sf_list:\n",
    "    pbar.set_postfix(acronym=sf)\n",
    "    mimic_sf = mimic_df[mimic_df['sf'] == sf].reset_index(drop=True)\n",
    "    mimic_sf = mimic_sf[cols]\n",
    "    n_mimic_sf = mimic_sf.shape[0]\n",
    "    n_test = int(n_mimic_sf * 0.2)\n",
    "    n_val = int(n_mimic_sf * 0.2)\n",
    "    train_idx, test_idx = train_test_split(np.arange(n_mimic_sf), test_size=n_test, random_state=42)\n",
    "    train_idx, val_idx = train_test_split(train_idx, test_size=n_val, random_state=42)\n",
    "\n",
    "    mimic_train += mimic_sf.iloc[train_idx].to_dict(orient='records')\n",
    "    mimic_val += mimic_sf.iloc[val_idx].to_dict(orient='records')\n",
    "    mimic_test += mimic_sf.iloc[test_idx].to_dict(orient='records')\n",
    "\n",
    "casi_train = Dataset.from_list(casi_train)\n",
    "casi_val = Dataset.from_list(casi_val)\n",
    "casi_test = Dataset.from_list(casi_test)\n",
    "casi_dataset = DatasetDict(dict(train=casi_train, val=casi_val, test=casi_test))\n",
    "\n",
    "mimic_train = Dataset.from_list(mimic_train)\n",
    "mimic_val = Dataset.from_list(mimic_val)\n",
    "mimic_test = Dataset.from_list(mimic_test)\n",
    "mimic_dataset = DatasetDict(dict(train=mimic_train, val=mimic_val, test=mimic_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets to disk\n",
    "DATA_DIR = '/data'\n",
    "casi_outdir = osp.join(DATA_DIR, 'casi-sense-preprocessed')\n",
    "os.makedirs(casi_outdir, exist_ok=True)\n",
    "casi_dataset.save_to_disk(casi_outdir)\n",
    "\n",
    "mimic_outdir = osp.join(DATA_DIR, 'mimic-iii-sense-preprocessed')\n",
    "os.makedirs(mimic_outdir, exist_ok=True)\n",
    "mimic_dataset.save_to_disk(mimic_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save the short-form to long-form mapping in the preprocessed datasets\n",
    "with open(osp.join(casi_outdir, 'sf_lf_map.json'), 'w') as fh:\n",
    "    json.dump(sf_lf_map, fh)\n",
    "\n",
    "with open(osp.join(mimic_outdir, 'sf_lf_map.json'), 'w') as fh:\n",
    "    json.dump(sf_lf_map, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
